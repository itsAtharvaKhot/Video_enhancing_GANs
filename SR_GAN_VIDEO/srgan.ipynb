{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPHNil2WiId18B4bf51ER+4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"f7vCaCWsQwzU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748000568137,"user_tz":-330,"elapsed":53836,"user":{"displayName":"Atharva Khot","userId":"04608416490032978917"}},"outputId":"e809c736-eeee-419a-af54-e683cbbba96e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1 GPU(s): [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","Will use GPU for processing\n","Creating SRGAN model...\n","Successfully loaded weights from /content/gan_generator.h5\n","Input video: 320x240 at 15.0 FPS, 205 frames\n","Output video will be: 1280x960 at 15.0 FPS\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing video:   0%|          | 0/205 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Testing first frame...\n"]},{"output_type":"stream","name":"stderr","text":["Processing video:   1%|          | 2/205 [00:10<14:50,  4.39s/it]"]},{"output_type":"stream","name":"stdout","text":["First frame processed successfully, dimensions: (960, 1280, 3)\n"]},{"output_type":"stream","name":"stderr","text":["Processing video: 100%|██████████| 205/205 [00:51<00:00,  4.00it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Processed 205 frames in 51.24 seconds\n","Average processing speed: 4.00 fps\n","Enhanced video saved to: /content/enhanced_output.mp4\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import os\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import cv2\n","from tqdm import tqdm\n","\n","# Remove the problematic GPU memory configuration\n","# Instead just print GPU availability\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    print(f\"Found {len(gpus)} GPU(s): {gpus}\")\n","    print(\"Will use GPU for processing\")\n","else:\n","    print(\"No GPU found, using CPU for processing\")\n","\n","def create_sr_model():\n","    \"\"\"Create the SRGAN model architecture directly.\"\"\"\n","\n","    # Input layer\n","    inputs = tf.keras.layers.Input(shape=(None, None, 3))\n","\n","    # First convolution block\n","    x = tf.keras.layers.Conv2D(64, kernel_size=9, padding='same')(inputs)\n","    x = tf.keras.layers.PReLU(shared_axes=[1, 2])(x)\n","    skip = x\n","\n","    # Residual blocks\n","    for _ in range(16):\n","        res = x\n","        x = tf.keras.layers.Conv2D(64, kernel_size=3, padding='same')(x)\n","        x = tf.keras.layers.BatchNormalization()(x)\n","        x = tf.keras.layers.PReLU(shared_axes=[1, 2])(x)\n","        x = tf.keras.layers.Conv2D(64, kernel_size=3, padding='same')(x)\n","        x = tf.keras.layers.BatchNormalization()(x)\n","        x = tf.keras.layers.Add()([res, x])\n","\n","    # Post-residual convolution\n","    x = tf.keras.layers.Conv2D(64, kernel_size=3, padding='same')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.Add()([skip, x])\n","\n","    # Upsampling blocks\n","    for _ in range(2):\n","        x = tf.keras.layers.Conv2D(256, kernel_size=3, padding='same')(x)\n","        x = tf.keras.layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(x)\n","        x = tf.keras.layers.PReLU(shared_axes=[1, 2])(x)\n","\n","    # Output layer\n","    x = tf.keras.layers.Conv2D(3, kernel_size=9, padding='same', activation='tanh')(x)\n","    x = tf.keras.layers.Lambda(lambda x: (x + 1) * 127.5)(x)\n","\n","    model = tf.keras.models.Model(inputs=inputs, outputs=x)\n","    return model\n","\n","def enhance_frame(model, frame):\n","    \"\"\"Enhance a single frame using the SRGAN model.\"\"\"\n","    # Convert to RGB (OpenCV loads as BGR)\n","    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Convert to float and normalize to 0-1\n","    input_frame = rgb_frame.astype(np.float32) / 255.0\n","\n","    # Add batch dimension\n","    input_tensor = np.expand_dims(input_frame, axis=0)\n","\n","    # Get super-resolution result\n","    sr_tensor = model.predict(input_tensor, verbose=0)\n","\n","    # Remove batch dimension and convert back to uint8\n","    sr_frame = np.squeeze(sr_tensor, axis=0)\n","    sr_frame = np.clip(sr_frame, 0, 255).astype(np.uint8)\n","\n","    # Convert back to BGR for OpenCV\n","    sr_bgr = cv2.cvtColor(sr_frame, cv2.COLOR_RGB2BGR)\n","\n","    return sr_bgr\n","\n","def process_video(input_path, output_path, weights_path=None):\n","    \"\"\"Process video with SRGAN enhancement.\"\"\"\n","    if not os.path.exists(input_path):\n","        print(f\"Error: Input video file not found at {input_path}\")\n","        return False\n","\n","    # Create model\n","    print(\"Creating SRGAN model...\")\n","    model = create_sr_model()\n","\n","    # Load weights if provided\n","    if weights_path and os.path.exists(weights_path):\n","        try:\n","            model.load_weights(weights_path)\n","            print(f\"Successfully loaded weights from {weights_path}\")\n","        except Exception as e:\n","            print(f\"Warning: Failed to load weights: {e}\")\n","            print(\"Proceeding with uninitialized model - results will be poor quality\")\n","    else:\n","        print(\"No weights provided or weights file not found\")\n","        print(\"Proceeding with uninitialized model - results will be poor quality\")\n","\n","    # Open video\n","    cap = cv2.VideoCapture(input_path)\n","    if not cap.isOpened():\n","        print(f\"Error: Could not open video file {input_path}\")\n","        return False\n","\n","    # Get video properties\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","    print(f\"Input video: {width}x{height} at {fps} FPS, {frame_count} frames\")\n","\n","    # New dimensions (4x upscale)\n","    new_width = width * 4\n","    new_height = height * 4\n","    print(f\"Output video will be: {new_width}x{new_height} at {fps} FPS\")\n","\n","    # Create output video writer\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n","\n","    # Process video\n","    start_time = time.time()\n","    processed_frames = 0\n","\n","    # Process frames with progress bar\n","    pbar = tqdm(total=frame_count, desc=\"Processing video\")\n","\n","    # Try processing just the first frame to ensure everything works\n","    ret, frame = cap.read()\n","    if ret:\n","        try:\n","            print(\"Testing first frame...\")\n","            enhanced = enhance_frame(model, frame)\n","            out.write(enhanced)\n","            processed_frames += 1\n","            pbar.update(1)\n","            print(f\"First frame processed successfully, dimensions: {enhanced.shape}\")\n","        except Exception as e:\n","            print(f\"Error processing first frame: {e}\")\n","            cap.release()\n","            out.release()\n","            pbar.close()\n","            return False\n","\n","    # Reset video capture\n","    cap.set(cv2.CAP_PROP_POS_FRAMES, 1)  # Start from second frame\n","\n","    # Process the rest of the frames\n","    try:\n","        while True:\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","\n","            enhanced = enhance_frame(model, frame)\n","            out.write(enhanced)\n","            processed_frames += 1\n","            pbar.update(1)\n","\n","    except Exception as e:\n","        print(f\"\\nError during processing: {e}\")\n","        return False\n","\n","    finally:\n","        # Clean up\n","        cap.release()\n","        out.release()\n","        pbar.close()\n","\n","    # Final stats\n","    total_time = time.time() - start_time\n","    print(f\"\\nProcessed {processed_frames} frames in {total_time:.2f} seconds\")\n","    print(f\"Average processing speed: {processed_frames / total_time:.2f} fps\")\n","    print(f\"Enhanced video saved to: {output_path}\")\n","\n","    return True\n","\n","# For direct usage\n","if __name__ == \"__main__\":\n","    # Example usage\n","    input_video = \"/content/SampleVideo_360x240_1mb.mp4\"\n","    output_video = \"/content/enhanced_output.mp4\"\n","    weights_file = \"/content/gan_generator.h5\"\n","\n","    process_video(input_video, output_video, weights_file)"]}]}