{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11515714,"sourceType":"datasetVersion","datasetId":7221676},{"sourceId":11516122,"sourceType":"datasetVersion","datasetId":7221991},{"sourceId":11526329,"sourceType":"datasetVersion","datasetId":7228965}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y torchvision torchaudio pytorch-lightning lightning torch-tensorrt\n\n!pip install torchvision\n!pip install torchaudio\n\n# Install compatible PyTorch Lightning\n!pip install pytorch-lightning>=2.2.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T11:57:03.724436Z","iopub.execute_input":"2025-05-23T11:57:03.725341Z","iopub.status.idle":"2025-05-23T12:00:03.931482Z","shell.execute_reply.started":"2025-05-23T11:57:03.725312Z","shell.execute_reply":"2025-05-23T12:00:03.930685Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Found existing installation: torchvision 0.20.1+cu124\nUninstalling torchvision-0.20.1+cu124:\n  Successfully uninstalled torchvision-0.20.1+cu124\nFound existing installation: torchaudio 2.5.1+cu124\nUninstalling torchaudio-2.5.1+cu124:\n  Successfully uninstalled torchaudio-2.5.1+cu124\nFound existing installation: pytorch-lightning 2.5.1\nUninstalling pytorch-lightning-2.5.1:\n  Successfully uninstalled pytorch-lightning-2.5.1\n\u001b[33mWARNING: Skipping lightning as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping torch-tensorrt as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting torchvision\n  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nCollecting torch==2.7.0 (from torchvision)\n  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (4.13.1)\nCollecting sympy>=1.13.3 (from torch==2.7.0->torchvision)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (2025.3.2)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0->torchvision)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0->torchvision)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0->torchvision)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0->torchvision)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0->torchvision)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.3.0 (from torch==2.7.0->torchvision)\n  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->torchvision) (75.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n  Attempting uninstall: triton\n    Found existing installation: triton 3.1.0\n    Uninstalling triton-3.1.0:\n      Successfully uninstalled triton-3.1.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu124\n    Uninstalling torch-2.5.1+cu124:\n      Successfully uninstalled torch-2.5.1+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.7.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0\nCollecting torchaudio\n  Downloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: torch==2.7.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.7.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (4.13.1)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (1.11.1.6)\nRequirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchaudio) (3.3.0)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->torchaudio) (75.1.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->torchaudio) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0->torchaudio) (3.0.2)\nDownloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torchaudio\nSuccessfully installed torchaudio-2.7.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:00:03.933190Z","iopub.execute_input":"2025-05-23T12:00:03.933409Z","iopub.status.idle":"2025-05-23T12:00:08.149608Z","shell.execute_reply.started":"2025-05-23T12:00:03.933389Z","shell.execute_reply":"2025-05-23T12:00:08.148982Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.143-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.7.0)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.22.0)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\nRequirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.3.0)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=1.8.0->ultralytics) (75.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.143-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.143 ultralytics-thop-2.0.14\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -q basicsr realesrgan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:00:08.150525Z","iopub.execute_input":"2025-05-23T12:00:08.150827Z","iopub.status.idle":"2025-05-23T12:00:18.141143Z","shell.execute_reply.started":"2025-05-23T12:00:08.150787Z","shell.execute_reply":"2025-05-23T12:00:18.140342Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Run this BEFORE importing basicsr\nimport importlib\nimport sys\nimport types\nimport torch\nimport torchvision\n\n# Define the missing function directly\ndef rgb_to_grayscale_patch(tensor, num_output_channels=1):\n    \n    if tensor.shape[-3] != 3:\n        raise ValueError(\"Input tensor must have 3 channels (RGB)\")\n        \n    # Use the existing implementation from functional\n    from torchvision.transforms import functional as F\n    return F.rgb_to_grayscale(tensor, num_output_channels)\n\n# Create a module-like object\nfunctional_tensor = types.ModuleType('torchvision.transforms.functional_tensor')\nfunctional_tensor.rgb_to_grayscale = rgb_to_grayscale_patch\n\n# Add the module to sys.modules so it can be imported\nsys.modules['torchvision.transforms.functional_tensor'] = functional_tensor\n\n# Also add it to torchvision.transforms\ntorchvision.transforms.functional_tensor = functional_tensor\n\nprint(\"Created and registered torchvision.transforms.functional_tensor with rgb_to_grayscale function\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:00:18.142181Z","iopub.execute_input":"2025-05-23T12:00:18.142443Z","iopub.status.idle":"2025-05-23T12:00:21.453331Z","shell.execute_reply.started":"2025-05-23T12:00:18.142415Z","shell.execute_reply":"2025-05-23T12:00:21.452601Z"}},"outputs":[{"name":"stdout","text":"Created and registered torchvision.transforms.functional_tensor with rgb_to_grayscale function\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nprint(hasattr(torch._dynamo, \"mark_static_address\"))","metadata":{"execution":{"iopub.status.busy":"2025-05-23T12:00:21.454788Z","iopub.execute_input":"2025-05-23T12:00:21.455085Z","iopub.status.idle":"2025-05-23T12:00:21.459234Z","shell.execute_reply.started":"2025-05-23T12:00:21.455067Z","shell.execute_reply":"2025-05-23T12:00:21.458546Z"},"trusted":true},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\n\n# Check PyTorch version\nprint(f\"PyTorch Version: {torch.__version__}\")\n\n# Check if CUDA (GPU) is available\nif torch.cuda.is_available():\n    print(f\"CUDA is available! GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"CUDA is not available, running on CPU.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-05-23T12:00:21.460113Z","iopub.execute_input":"2025-05-23T12:00:21.460504Z","iopub.status.idle":"2025-05-23T12:00:21.589309Z","shell.execute_reply.started":"2025-05-23T12:00:21.460477Z","shell.execute_reply":"2025-05-23T12:00:21.588741Z"},"trusted":true},"outputs":[{"name":"stdout","text":"PyTorch Version: 2.7.0+cu126\nCUDA is available! GPU: Tesla T4\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from basicsr.archs.rrdbnet_arch import RRDBNet\nfrom basicsr.utils.download_util import load_file_from_url\nfrom realesrgan import RealESRGANer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:00:21.590004Z","iopub.execute_input":"2025-05-23T12:00:21.590189Z","iopub.status.idle":"2025-05-23T12:00:22.793612Z","shell.execute_reply.started":"2025-05-23T12:00:21.590174Z","shell.execute_reply":"2025-05-23T12:00:22.792766Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import os\nimport cv2\nimport gc\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom datetime import datetime\n\n# RealESRGAN imports\nfrom basicsr.archs.rrdbnet_arch import RRDBNet\nfrom basicsr.utils.download_util import load_file_from_url\nfrom realesrgan import RealESRGANer\n\nclass VideoEnhancer:\n    def __init__(self, model_name='RealESRGAN_x4plus', model_path=None, scale=4,\n                 denoise_strength=0.5, tile_size=512, half_precision=None, \n                 use_cuda=True, output_format='mp4v'):\n        \"\"\"\n        Initialize the VideoEnhancer with specified parameters.\n        \n        Args:\n            model_name (str): Name of the model to use.\n            model_path (str): Path to the model weights.\n            scale (int): Scale factor for upscaling.\n            denoise_strength (float): Strength of denoising.\n            tile_size (int): Tile size for processing large frames.\n            half_precision (bool): Whether to use half precision (FP16).\n            use_cuda (bool): Whether to use CUDA if available.\n            output_format (str): Format code for the output video.\n        \"\"\"\n        # Set CUDA availability\n        self.use_cuda = use_cuda and torch.cuda.is_available()\n        self.device = torch.device('cuda' if self.use_cuda else 'cpu')\n        \n        # Store parameters\n        self.scale = scale\n        self.model_name = model_name\n        self.denoise_strength = denoise_strength\n        self.upsampler = None\n        self.output_format = output_format\n        \n        # Set half precision based on CUDA availability if not specified\n        if half_precision is None:\n            half_precision = self.use_cuda\n\n        # Adjust tile size based on available GPU memory\n        self.tile_size = tile_size\n        if self.use_cuda:\n            try:\n                gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n                if gpu_mem < 4 and tile_size > 256:  # Less than 4GB VRAM\n                    self.tile_size = 256\n                elif gpu_mem < 8 and tile_size > 512:  # Less than 8GB VRAM\n                    self.tile_size = 512\n                print(f\"Detected {gpu_mem:.2f}GB GPU memory, using tile size: {self.tile_size}\")\n            except Exception as e:\n                print(f\"Error detecting GPU memory: {e}\")\n                print(f\"Using default tile size: {self.tile_size}\")\n\n        # Determine the model path\n        if model_path and os.path.exists(model_path) and os.path.getsize(model_path) > 1000:\n            print(f\"Using provided model path: {model_path}\")\n        else:\n            model_path = os.path.join('weights', f\"{model_name}.pth\")\n            \n            if not os.path.exists(model_path) or os.path.getsize(model_path) < 1000:\n                # Create weights directory if it doesn't exist\n                os.makedirs('weights', exist_ok=True)\n                \n                # Download model weights\n                if model_name == 'RealESRGAN_x4plus':\n                    model_url = 'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth'\n                    load_file_from_url(model_url, model_dir='weights')\n                elif model_name == 'RealESRGAN_x4plus_anime_6B':\n                    model_url = 'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth'\n                    load_file_from_url(model_url, model_dir='weights')\n                else:\n                    raise FileNotFoundError(f\"Model file not found at {model_path} and no download URL for {model_name}\")\n\n        print(f\"Using {model_name} model from: {model_path} with {scale}x upscaling\")\n        \n        try:\n            # Initialize RealESRGAN model\n            if model_name == 'RealESRGAN_x4plus':\n                model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=self.scale)\n            elif model_name == 'RealESRGAN_x4plus_anime_6B':\n                model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=6, num_grow_ch=32, scale=self.scale)\n            else:\n                raise ValueError(f\"Unsupported model name: {model_name}\")\n            \n            # Create the upsampler\n            self.upsampler = RealESRGANer(\n                scale=self.scale,\n                model_path=model_path,\n                model=model,\n                tile=self.tile_size,\n                tile_pad=32,\n                pre_pad=0,\n                half=half_precision,\n                device=self.device\n            )\n            \n        except Exception as e:\n            raise RuntimeError(f\"Failed to initialize model {model_name}: {e}\")\n        \n        self.model_attributes = {\n            'name': model_name,\n            'path': model_path,\n            'scale': scale,\n            'tile_size': self.tile_size,\n            'half_precision': half_precision,\n            'device': str(self.device)\n        }\n        \n        print(f\"VideoEnhancer initialized with {model_name} on {self.device}\")\n    \n    def enhance_frame(self, frame):\n        \"\"\"\n        Enhance a single video frame.\n        \n        Args:\n            frame: Input frame (OpenCV format, BGR)\n            \n        Returns:\n            Enhanced frame in the same format\n        \"\"\"\n        try:\n            h, w = frame.shape[:2]\n            max_dimension = 1280  # Maximum dimension to process at once\n            scale_factor = 1\n\n            # Resize large frames to avoid memory issues\n            if max(h, w) > max_dimension:\n                scale_factor = max_dimension / max(h, w)\n                new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n                frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)\n                print(f\"Resized frame from {h}x{w} to {new_h}x{new_w} for processing\")\n\n            # Convert BGR to RGB for processing\n            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n            # Clear CUDA cache before processing\n            if self.use_cuda:\n                torch.cuda.empty_cache()\n\n            # Enhance the frame\n            output, _ = self.upsampler.enhance(frame_rgb, outscale=self.scale)\n\n            # Convert back to BGR\n            output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n\n            # Clear CUDA cache after processing\n            if self.use_cuda:\n                torch.cuda.empty_cache()\n\n            return output\n\n        except RuntimeError as e:\n            if 'out of memory' in str(e).lower():\n                print(\"WARNING: GPU out of memory. Trying with smaller frame...\")\n                # If we hit OOM, resize frame more aggressively and try again\n                h, w = frame.shape[:2]\n                new_h, new_w = int(h * 0.5), int(w * 0.5)\n                small_frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)\n\n                if self.use_cuda:\n                    torch.cuda.empty_cache()\n\n                enhanced_small = self.enhance_frame(small_frame)  # Recursive call with smaller frame\n                return cv2.resize(enhanced_small, (w*self.scale, h*self.scale), interpolation=cv2.INTER_LANCZOS4)\n            else:\n                print(f\"Error enhancing frame: {e}\")\n                # Return upscaled original frame if enhancement fails\n                return cv2.resize(frame, (int(frame.shape[1]*self.scale), int(frame.shape[0]*self.scale)), \n                                interpolation=cv2.INTER_LANCZOS4)\n        except Exception as e:\n            print(f\"Error enhancing frame: {e}\")\n            # Return upscaled original frame if enhancement fails\n            return cv2.resize(frame, (int(frame.shape[1]*self.scale), int(frame.shape[0]*self.scale)), \n                            interpolation=cv2.INTER_LANCZOS4)\n    \n    def enhance_video(self, input_path, output_path=None, start_time=0, duration=None, \n                     sample_rate=1, resize_factor=1.0, show_progress=True, audio=True):\n        \"\"\"\n        Enhance a video file.\n        \n        Args:\n            input_path (str): Path to the input video.\n            output_path (str): Path for the enhanced output video. If None, a default name will be used.\n            start_time (float): Start time in seconds to begin processing.\n            duration (float): Duration in seconds to process. If None, process until the end.\n            sample_rate (int): Process 1 out of every 'sample_rate' frames.\n            resize_factor (float): Factor to resize the original frames before enhancing.\n            show_progress (bool): Whether to show a progress bar.\n            audio (bool): Whether to copy audio from the original video.\n            \n        Returns:\n            str: Path to the enhanced video.\n        \"\"\"\n        if not os.path.exists(input_path):\n            raise FileNotFoundError(f\"Input video not found: {input_path}\")\n        \n        # Generate default output path if not provided\n        if output_path is None:\n            basename = os.path.basename(input_path)\n            name, ext = os.path.splitext(basename)\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            output_path = f\"{name}_enhanced_{timestamp}{ext}\"\n        \n        # Create output directory if it doesn't exist\n        output_dir = os.path.dirname(output_path)\n        if output_dir and not os.path.exists(output_dir):\n            os.makedirs(output_dir, exist_ok=True)\n        \n        # Open the input video\n        cap = cv2.VideoCapture(input_path)\n        if not cap.isOpened():\n            raise RuntimeError(f\"Could not open video: {input_path}\")\n        \n        # Get video properties\n        fps = cap.get(cv2.CAP_PROP_FPS)\n        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        \n        # Calculate frame positions for start_time and duration\n        start_frame = int(start_time * fps)\n        if duration is not None:\n            end_frame = start_frame + int(duration * fps)\n        else:\n            end_frame = frame_count\n        \n        # Calculate the total frames to process considering sample_rate\n        total_frames = (end_frame - start_frame) // sample_rate\n        \n        # Print video information\n        print(f\"Video Info: {width}x{height}, {fps} fps, {frame_count} frames\")\n        print(f\"Processing {total_frames} frames from frame {start_frame} to {end_frame} (sample rate: {sample_rate})\")\n        \n        # Calculate new dimensions based on resize_factor and scale\n        if resize_factor != 1.0:\n            width = int(width * resize_factor)\n            height = int(height * resize_factor)\n            print(f\"Resizing input frames to: {width}x{height}\")\n        \n        # Calculate output dimensions based on scale\n        out_width = int(width * self.scale)\n        out_height = int(height * self.scale)\n        print(f\"Output dimensions: {out_width}x{out_height}\")\n        \n        # Find the appropriate video codec\n        if self.output_format == 'mp4v':\n            fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Default MP4 codec\n        elif self.output_format == 'avc1':\n            fourcc = cv2.VideoWriter_fourcc(*'avc1')  # H.264 codec\n        elif self.output_format == 'H264':\n            fourcc = cv2.VideoWriter_fourcc(*'H264')  # Another variant of H.264\n        elif self.output_format == 'XVID':\n            fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Xvid codec\n        else:\n            # Fallback to MJPG which is widely supported\n            fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n            output_path = os.path.splitext(output_path)[0] + '.avi'\n            print(f\"Using MJPG codec with .avi container. Output: {output_path}\")\n        \n        # Create a video writer\n        out = cv2.VideoWriter(output_path, fourcc, fps, (out_width, out_height))\n        if not out.isOpened():\n            raise RuntimeError(f\"Could not create output video writer: {output_path}\")\n        \n        # Set the starting position\n        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n        \n        # Process the video frame by frame\n        processed_frames = 0\n        current_frame = start_frame\n        \n        try:\n            # Create progress bar if requested\n            pbar = tqdm(total=total_frames, disable=not show_progress)\n            \n            while current_frame < end_frame:\n                ret, frame = cap.read()\n                if not ret:\n                    break\n                \n                # Process 1 out of every sample_rate frames\n                if (current_frame - start_frame) % sample_rate == 0:\n                    # Resize input frame if needed\n                    if resize_factor != 1.0:\n                        frame = cv2.resize(frame, (width, height), interpolation=cv2.INTER_AREA)\n                    \n                    # Enhance the frame\n                    enhanced_frame = self.enhance_frame(frame)\n                    \n                    # Write the enhanced frame\n                    out.write(enhanced_frame)\n                    \n                    # Update progress\n                    processed_frames += 1\n                    pbar.update(1)\n                    \n                    # Free memory\n                    del enhanced_frame\n                    if self.use_cuda:\n                        torch.cuda.empty_cache()\n                \n                current_frame += 1\n                \n                # Keyboard interrupt check (press 'q' to stop)\n                if cv2.waitKey(1) & 0xFF == ord('q'):\n                    print(\"\\nProcessing interrupted by user\")\n                    break\n            \n            pbar.close()\n        \n        except Exception as e:\n            print(f\"Error during video processing: {e}\")\n            import traceback\n            traceback.print_exc()\n        finally:\n            # Release resources\n            cap.release()\n            out.release()\n            cv2.destroyAllWindows()\n            \n            # Force garbage collection\n            gc.collect()\n            if self.use_cuda:\n                torch.cuda.empty_cache()\n        \n        print(f\"Processed {processed_frames} frames. Enhanced video saved to: {output_path}\")\n        \n        # Add audio from the original video if requested\n        if audio:\n            try:\n                temp_output = output_path + \".temp\" + os.path.splitext(output_path)[1]\n                os.rename(output_path, temp_output)\n                \n                # Use FFmpeg to add audio from the original video\n                import subprocess\n                ffmpeg_cmd = [\n                    'ffmpeg', '-i', temp_output, '-i', input_path, \n                    '-c:v', 'copy', '-map', '0:v:0', '-map', '1:a:0?', \n                    '-shortest', output_path, '-y'\n                ]\n                \n                print(\"Adding audio from original video...\")\n                subprocess.run(ffmpeg_cmd, check=True, capture_output=True)\n                \n                # Remove the temporary file\n                os.remove(temp_output)\n                print(\"Audio added successfully\")\n            except Exception as e:\n                print(f\"Warning: Could not add audio: {e}\")\n                # If adding audio fails, rename the temp file back\n                if os.path.exists(temp_output):\n                    os.rename(temp_output, output_path)\n        \n        return output_path\n    \n    def get_model_info(self):\n        \"\"\"Return information about the currently loaded model\"\"\"\n        return self.model_attributes\n\n\ndef enhance_video_file(input_path, output_path=None, model_name='RealESRGAN_x4plus', model_path=None, \n                     scale=2, tile_size=512, use_cuda=True, start_time=0, duration=None, \n                     sample_rate=1, resize_factor=1.0, copy_audio=True, output_format='mp4v'):\n    \"\"\"\n    Simple function to enhance a video file with default parameters.\n    \n    Args:\n        input_path (str): Path to the input video file\n        output_path (str): Path for the enhanced output video. If None, a default name will be used.\n        model_name (str): Model to use ('RealESRGAN_x4plus' or 'RealESRGAN_x4plus_anime_6B')\n        model_path (str): Optional path to model weights\n        scale (int): Upscaling factor (2, 3, or 4)\n        tile_size (int): Tile size for processing large frames\n        use_cuda (bool): Whether to use CUDA if available\n        start_time (float): Start time in seconds\n        duration (float): Duration to process in seconds (None for full video)\n        sample_rate (int): Process 1 out of every N frames\n        resize_factor (float): Resize input frames before enhancement\n        copy_audio (bool): Whether to copy audio from original video\n        output_format (str): Output video codec format ('mp4v', 'avc1', 'H264', 'XVID')\n    \n    Returns:\n        str: Path to the enhanced video\n    \"\"\"\n    # Initialize the enhancer\n    enhancer = VideoEnhancer(\n        model_name=model_name,\n        model_path=model_path,\n        scale=scale,\n        tile_size=tile_size,\n        use_cuda=use_cuda,\n        output_format=output_format\n    )\n    \n    # Enhance the video\n    output_path = enhancer.enhance_video(\n        input_path=input_path,\n        output_path=output_path,\n        start_time=start_time,\n        duration=duration,\n        sample_rate=sample_rate,\n        resize_factor=resize_factor,\n        audio=copy_audio\n    )\n    \n    print(f\"Enhancement complete! Output saved to: {output_path}\")\n    return output_path\n\n\ndef main():\n    \"\"\"Example usage of the video enhancer\"\"\"\n    # Example: Enhance a video with default settings\n    # input_video = \"/kaggle/input/videodemo/enhanced_demo1.mp4\"  # Replace with your video path\n    # enhance_video_file(input_video)\n    \n    # Example: Enhance with custom settings\n    enhance_video_file(\n        input_path=\"/kaggle/input/demo1enhance/demo.mp4\",\n        output_path=\"enhanced_output.mp4\",\n        model_name=\"RealESRGAN_x4plus\",\n        scale=4,\n        sample_rate=2,  # Process every other frame for speed\n        resize_factor=0.5  # Resize to half size before enhancing\n    )\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-05-23T12:03:02.614257Z","iopub.execute_input":"2025-05-23T12:03:02.615076Z","iopub.status.idle":"2025-05-23T12:10:09.379019Z","shell.execute_reply.started":"2025-05-23T12:03:02.615039Z","shell.execute_reply":"2025-05-23T12:10:09.378184Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Detected 14.74GB GPU memory, using tile size: 512\nUsing RealESRGAN_x4plus model from: weights/RealESRGAN_x4plus.pth with 4x upscaling\nVideoEnhancer initialized with RealESRGAN_x4plus on cuda\nVideo Info: 1920x1080, 18.0 fps, 199 frames\nProcessing 99 frames from frame 0 to 199 (sample rate: 2)\nResizing input frames to: 960x540\nOutput dimensions: 3840x2160\n","output_type":"stream"},{"name":"stderr","text":"\n  0%|          | 0/99 [00:00<?, ?it/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n  1%|          | 1/99 [00:04<06:32,  4.00s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n  2%|▏         | 2/99 [00:07<06:20,  3.92s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n  3%|▎         | 3/99 [00:11<06:14,  3.90s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n  4%|▍         | 4/99 [00:15<06:10,  3.90s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n  5%|▌         | 5/99 [00:19<06:07,  3.90s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n  6%|▌         | 6/99 [00:23<06:04,  3.92s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n  7%|▋         | 7/99 [00:27<06:00,  3.92s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n  8%|▊         | 8/99 [00:31<05:57,  3.93s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n  9%|▉         | 9/99 [00:35<05:53,  3.93s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 10%|█         | 10/99 [00:39<05:49,  3.93s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 11%|█         | 11/99 [00:43<05:46,  3.94s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 12%|█▏        | 12/99 [00:47<05:43,  3.94s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 13%|█▎        | 13/99 [00:51<05:38,  3.94s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 14%|█▍        | 14/99 [00:55<05:36,  3.96s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 15%|█▌        | 15/99 [00:59<05:33,  3.97s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 16%|█▌        | 16/99 [01:03<05:29,  3.97s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 17%|█▋        | 17/99 [01:07<05:26,  3.98s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 18%|█▊        | 18/99 [01:11<05:23,  3.99s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 19%|█▉        | 19/99 [01:15<05:20,  4.00s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 20%|██        | 20/99 [01:19<05:17,  4.01s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 21%|██        | 21/99 [01:23<05:13,  4.02s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 22%|██▏       | 22/99 [01:27<05:10,  4.03s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 23%|██▎       | 23/99 [01:31<05:06,  4.04s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 24%|██▍       | 24/99 [01:35<05:03,  4.04s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 25%|██▌       | 25/99 [01:39<04:58,  4.04s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 26%|██▋       | 26/99 [01:43<04:55,  4.05s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 27%|██▋       | 27/99 [01:47<04:52,  4.06s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 28%|██▊       | 28/99 [01:51<04:49,  4.08s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 29%|██▉       | 29/99 [01:55<04:46,  4.09s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 30%|███       | 30/99 [01:59<04:43,  4.10s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 31%|███▏      | 31/99 [02:04<04:39,  4.12s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 32%|███▏      | 32/99 [02:08<04:36,  4.12s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 33%|███▎      | 33/99 [02:12<04:32,  4.12s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 34%|███▍      | 34/99 [02:16<04:28,  4.13s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 35%|███▌      | 35/99 [02:20<04:25,  4.14s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 36%|███▋      | 36/99 [02:24<04:21,  4.16s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 37%|███▋      | 37/99 [02:29<04:18,  4.17s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 38%|███▊      | 38/99 [02:33<04:15,  4.18s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 39%|███▉      | 39/99 [02:37<04:11,  4.20s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 40%|████      | 40/99 [02:41<04:08,  4.21s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 41%|████▏     | 41/99 [02:45<04:04,  4.22s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 42%|████▏     | 42/99 [02:50<04:01,  4.23s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 43%|████▎     | 43/99 [02:54<03:57,  4.24s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 44%|████▍     | 44/99 [02:58<03:53,  4.24s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 45%|████▌     | 45/99 [03:02<03:49,  4.25s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 46%|████▋     | 46/99 [03:07<03:46,  4.27s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 47%|████▋     | 47/99 [03:11<03:42,  4.28s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 48%|████▊     | 48/99 [03:15<03:38,  4.28s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 49%|████▉     | 49/99 [03:20<03:34,  4.29s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 51%|█████     | 50/99 [03:24<03:30,  4.30s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 52%|█████▏    | 51/99 [03:28<03:26,  4.31s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 53%|█████▎    | 52/99 [03:33<03:23,  4.33s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 54%|█████▎    | 53/99 [03:37<03:19,  4.33s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 55%|█████▍    | 54/99 [03:41<03:15,  4.34s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 56%|█████▌    | 55/99 [03:46<03:11,  4.35s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 57%|█████▋    | 56/99 [03:50<03:06,  4.35s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 58%|█████▊    | 57/99 [03:54<03:03,  4.36s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 59%|█████▊    | 58/99 [03:59<02:59,  4.37s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 60%|█████▉    | 59/99 [04:03<02:55,  4.38s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 61%|██████    | 60/99 [04:08<02:51,  4.39s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 62%|██████▏   | 61/99 [04:12<02:46,  4.39s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 63%|██████▎   | 62/99 [04:17<02:42,  4.40s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 64%|██████▎   | 63/99 [04:21<02:38,  4.40s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 65%|██████▍   | 64/99 [04:25<02:34,  4.40s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 66%|██████▌   | 65/99 [04:30<02:29,  4.41s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 67%|██████▋   | 66/99 [04:34<02:25,  4.41s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 68%|██████▊   | 67/99 [04:39<02:21,  4.42s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 69%|██████▊   | 68/99 [04:43<02:16,  4.41s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 70%|██████▉   | 69/99 [04:47<02:12,  4.42s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 71%|███████   | 70/99 [04:52<02:08,  4.43s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 72%|███████▏  | 71/99 [04:56<02:04,  4.43s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 73%|███████▎  | 72/99 [05:01<01:59,  4.44s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 74%|███████▎  | 73/99 [05:05<01:55,  4.44s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 75%|███████▍  | 74/99 [05:10<01:51,  4.44s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 76%|███████▌  | 75/99 [05:14<01:46,  4.45s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 77%|███████▋  | 76/99 [05:19<01:42,  4.45s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 78%|███████▊  | 77/99 [05:23<01:37,  4.45s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 79%|███████▉  | 78/99 [05:28<01:33,  4.46s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 80%|███████▉  | 79/99 [05:32<01:29,  4.46s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 81%|████████  | 80/99 [05:36<01:24,  4.46s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 82%|████████▏ | 81/99 [05:41<01:20,  4.46s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 83%|████████▎ | 82/99 [05:45<01:15,  4.47s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 84%|████████▍ | 83/99 [05:50<01:11,  4.47s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 85%|████████▍ | 84/99 [05:54<01:06,  4.47s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 86%|████████▌ | 85/99 [05:59<01:02,  4.47s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 87%|████████▋ | 86/99 [06:03<00:58,  4.47s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 88%|████████▊ | 87/99 [06:08<00:53,  4.46s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 89%|████████▉ | 88/99 [06:12<00:48,  4.44s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 90%|████████▉ | 89/99 [06:17<00:44,  4.43s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 91%|█████████ | 90/99 [06:21<00:39,  4.43s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 92%|█████████▏| 91/99 [06:25<00:35,  4.42s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 93%|█████████▎| 92/99 [06:30<00:30,  4.41s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 94%|█████████▍| 93/99 [06:34<00:26,  4.41s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 95%|█████████▍| 94/99 [06:39<00:22,  4.42s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 96%|█████████▌| 95/99 [06:43<00:17,  4.43s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 97%|█████████▋| 96/99 [06:47<00:13,  4.42s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 98%|█████████▊| 97/99 [06:52<00:08,  4.43s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n 99%|█████████▉| 98/99 [06:56<00:04,  4.43s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 99/99 [07:01<00:00,  4.43s/it]\u001b[A","output_type":"stream"},{"name":"stdout","text":"\tTile 1/4\n\tTile 2/4\n\tTile 3/4\n\tTile 4/4\n","output_type":"stream"},{"name":"stderr","text":"\n100it [07:05,  4.26s/it]                       \u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Processed 100 frames. Enhanced video saved to: enhanced_output.mp4\nAdding audio from original video...\nAudio added successfully\nEnhancement complete! Output saved to: enhanced_output.mp4\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}