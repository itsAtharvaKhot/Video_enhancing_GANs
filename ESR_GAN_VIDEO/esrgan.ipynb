{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "5ESlXy_biv12",
        "outputId": "d130f066-90e1-4221-f816-e67bf9a4e1f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Using device: cuda\n",
            "Using model file: /content/RRDB_ESRGAN_x4.pth\n",
            "Model loaded successfully.\n",
            "Processing video: /content/animation144p_input.mp4\n",
            "Processing video: /content/animation144p_input.mp4\n",
            "Output video: enhanced_animation144p_input.mp4\n",
            "Total frames: 252\n",
            "FPS: 25.0\n",
            "Original resolution: 256x144\n",
            "Enhanced resolution: 1024x576\n",
            "Processing: 252/252 (100.00%) | Speed: 2.77 fps | ETA: 00:00:00\n",
            "Video processing complete! Total time: 91.05 seconds\n",
            "Processing complete! Downloading the enhanced video...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ee8407ef-af2e-4ff8-9b54-706690099181\", \"enhanced_animation144p_input.mp4\", 4576605)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'enhanced_animation144p_input.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python numpy pillow\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import glob\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML\n",
        "import time\n",
        "\n",
        "# Define the ESRGAN model architecture\n",
        "class ResidualDenseBlock(torch.nn.Module):\n",
        "    def __init__(self, nf=64, gc=32, bias=True):\n",
        "        super(ResidualDenseBlock, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(nf, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv2 = torch.nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv3 = torch.nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv4 = torch.nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv5 = torch.nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=bias)\n",
        "        self.lrelu = torch.nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
        "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "\n",
        "class RRDB(torch.nn.Module):\n",
        "    def __init__(self, nf, gc=32):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.RDB1 = ResidualDenseBlock(nf, gc)\n",
        "        self.RDB2 = ResidualDenseBlock(nf, gc)\n",
        "        self.RDB3 = ResidualDenseBlock(nf, gc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.RDB1(x)\n",
        "        out = self.RDB2(out)\n",
        "        out = self.RDB3(out)\n",
        "        return out * 0.2 + x\n",
        "\n",
        "\n",
        "class RRDBNet(torch.nn.Module):\n",
        "    def __init__(self, in_nc=3, out_nc=3, nf=64, nb=23, gc=32, scale=4, upscale=True):\n",
        "        super(RRDBNet, self).__init__()\n",
        "        self.scale = scale\n",
        "        self.upscale = upscale\n",
        "\n",
        "        self.conv_first = torch.nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
        "        self.RRDB_trunk = torch.nn.Sequential(*[RRDB(nf, gc) for _ in range(nb)])\n",
        "        self.trunk_conv = torch.nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "\n",
        "        # Upsampling\n",
        "        if upscale:\n",
        "            self.upconv1 = torch.nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "            if scale == 4:\n",
        "                self.upconv2 = torch.nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "            self.HRconv = torch.nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "            self.conv_last = torch.nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
        "            self.lrelu = torch.nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fea = self.conv_first(x)\n",
        "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
        "        fea = fea + trunk\n",
        "\n",
        "        if self.upscale:\n",
        "            fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "            if self.scale == 4:\n",
        "                fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "            out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
        "        else:\n",
        "            out = fea\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def load_model(model_path):\n",
        "    model = RRDBNet(scale=4)\n",
        "\n",
        "    # Load the state dictionary\n",
        "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "\n",
        "    # Often pre-trained models have different key names, so we need to process them\n",
        "    if 'params_ema' in state_dict:\n",
        "        state_dict = state_dict['params_ema']\n",
        "\n",
        "    # Create new OrderedDict that does not contain module.\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        if k.startswith('module.'):\n",
        "            name = k[7:]  # remove module.\n",
        "        else:\n",
        "            name = k\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    model.load_state_dict(new_state_dict, strict=True)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def enhance_image(model, img, device):\n",
        "    # Convert to RGB if needed and normalize\n",
        "    if len(img.shape) == 3 and img.shape[2] == 3:\n",
        "        img = img[:, :, [2, 1, 0]]  # BGR to RGB\n",
        "    img = img.astype(np.float32) / 255.\n",
        "\n",
        "    # Convert to tensor\n",
        "    img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(device)\n",
        "\n",
        "    # Inference\n",
        "    with torch.no_grad():\n",
        "        output = model(img)\n",
        "\n",
        "    # Convert back to numpy array\n",
        "    output = output.squeeze().float().cpu().clamp_(0, 1).detach().permute(1, 2, 0).numpy()\n",
        "    output = (output * 255.0).round().astype(np.uint8)\n",
        "\n",
        "    # Convert back to BGR for OpenCV\n",
        "    if output.shape[2] == 3:\n",
        "        output = output[:, :, [2, 1, 0]]\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def process_video(input_video, output_video, model, device='cpu', scale_factor=4):\n",
        "    # Open the input video\n",
        "    cap = cv2.VideoCapture(input_video)\n",
        "\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video, fourcc, fps, (width * scale_factor, height * scale_factor))\n",
        "\n",
        "    print(f\"Processing video: {input_video}\")\n",
        "    print(f\"Output video: {output_video}\")\n",
        "    print(f\"Total frames: {total_frames}\")\n",
        "    print(f\"FPS: {fps}\")\n",
        "    print(f\"Original resolution: {width}x{height}\")\n",
        "    print(f\"Enhanced resolution: {width*scale_factor}x{height*scale_factor}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    frame_count = 0\n",
        "\n",
        "    # Process video frame by frame\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Enhance the frame\n",
        "        enhanced_frame = enhance_image(model, frame, device)\n",
        "\n",
        "        # Write the enhanced frame\n",
        "        out.write(enhanced_frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        # Calculate progress and ETA\n",
        "        elapsed_time = time.time() - start_time\n",
        "        frames_per_second = frame_count / elapsed_time if elapsed_time > 0 else 0\n",
        "        remaining_frames = total_frames - frame_count\n",
        "        eta_seconds = remaining_frames / frames_per_second if frames_per_second > 0 else 0\n",
        "\n",
        "        # Format ETA as HH:MM:SS\n",
        "        eta_hours = int(eta_seconds // 3600)\n",
        "        eta_minutes = int((eta_seconds % 3600) // 60)\n",
        "        eta_seconds = int(eta_seconds % 60)\n",
        "\n",
        "        print(f\"Processing: {frame_count}/{total_frames} ({frame_count/total_frames*100:.2f}%) | \" +\n",
        "              f\"Speed: {frames_per_second:.2f} fps | \" +\n",
        "              f\"ETA: {eta_hours:02d}:{eta_minutes:02d}:{eta_seconds:02d}\", end='\\r')\n",
        "\n",
        "    # Release everything when done\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"\\nVideo processing complete! Total time: {elapsed_time:.2f} seconds\")\n",
        "    return output_video\n",
        "\n",
        "# Updated main Colab interface to use the uploaded files\n",
        "def main_colab_uploaded(input_video_path=\"demo.mp4\", model_path=\"RRDB_PSNR_x4.pth\"):\n",
        "    # Check if CUDA is available\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    print(f\"Using model file: {model_path}\")\n",
        "    try:\n",
        "        model = load_model(model_path)\n",
        "        model = model.to(device)\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Processing video: {input_video_path}\")\n",
        "\n",
        "    # Set output filename\n",
        "    input_filename = os.path.splitext(os.path.basename(input_video_path))[0]\n",
        "    output_video = f\"enhanced_{input_filename}.mp4\"\n",
        "\n",
        "    # Process the video\n",
        "    processed_file = process_video(input_video_path, output_video, model, device)\n",
        "\n",
        "    if processed_file:\n",
        "        # Download the enhanced video\n",
        "        print(\"Processing complete! Downloading the enhanced video...\")\n",
        "        files.download(output_video)\n",
        "        return output_video\n",
        "    else:\n",
        "        print(\"Video processing failed.\")\n",
        "        return None\n",
        "\n",
        "# Run the updated Colab interface with the uploaded files\n",
        "main_colab_uploaded(input_video_path=\"/content/animation144p_input.mp4\", model_path=\"/content/RRDB_ESRGAN_x4.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "24A-o-Qk2TZU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}